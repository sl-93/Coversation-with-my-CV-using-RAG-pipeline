{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u6oDsztBNnlSCp6Ev6x3OKyP7aGs30Cd",
      "authorship_tag": "ABX9TyOlxZe24zX+aJuZoGsnMwQL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sl-93/Coversation-with-my-CV-using-RAG-pipeline/blob/main/RAGPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I will be creating a RAG pipeline to communicate with my Resume.\n",
        "\n",
        "I will be using Chromadb as a vector database and TinyLlama as an LLM in the RAG pipeline."
      ],
      "metadata": {
        "id": "0gWWmgtBZHD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-qbhPLK-7uA",
        "outputId": "0e64443b-99a3-4a76-d9ea-f4a29f2ed85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing necessary libraries...\n",
            "Libraries installed successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing necessary libraries...\")\n",
        "!pip install -q transformers langchain chromadb gradio tiktoken langchain-community sentence-transformers pypdf\n",
        "\n",
        "print(\"Libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader # to read a document using langchain\n",
        "from langchain.chains import RetrievalQAWithSourcesChain # to build our RAG pipeline"
      ],
      "metadata": {
        "id": "J4a9ZsnZ_bMm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FILE_PATH = \"/content/drive/MyDrive/resume/Saeed_Lotfi.pdf\""
      ],
      "metadata": {
        "id": "0B9qD1XnCESh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Attempting to load data from: {DATA_FILE_PATH}\")\n",
        "\n",
        "loader = PyPDFLoader(DATA_FILE_PATH)\n",
        "raw_documents = loader.load()\n",
        "\n",
        "print(f\"Successfully loaded {len(raw_documents)} document(s)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xm-F8ZPEvGd",
        "outputId": "4449aedd-3b0c-4c5f-ee9e-f90476af3541"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load data from: /content/drive/MyDrive/resume/Saeed_Lotfi.pdf\n",
            "Successfully loaded 2 document(s)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(raw_documents):\n",
        "    print(f\"Page {i+1}:\")\n",
        "    print(doc.page_content[:300], \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR_Zgn4CGnVB",
        "outputId": "bf604e90-069c-4030-96c4-9805e3e9ad6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1:\n",
            "Saeed Lotfi\n",
            "AI developer at Sharif Hamrah\n",
            "Pazhouhan\n",
            "Master : Artiﬁcial intelligence and\n",
            "robotics At K.N.Toosi University of\n",
            "Technology\n",
            "Personal Information\n",
            "Age: 31 Years\n",
            "Gender: Male\n",
            "Location Province: Tehran\n",
            "Location City: Tehran\n",
            "Marital Status: Single\n",
            "Military Service\n",
            "Status:\n",
            "Completed\n",
            "Contact Det \n",
            "\n",
            "Page 2:\n",
            "www.jobvision.ir\n",
            "Languages\n",
            "Software\n",
            "Honors & Awards\n",
            "Projects & Academic experiences\n",
            "Papers & Books\n",
            "About Me\n",
            "English |  Advanced\n",
            "Microsoft Word |  Advanced\n",
            " \n",
            "Microsoft Excel |  Advanced\n",
            "Microsoft Powerpoint |  Advanced\n",
            " \n",
            "Python |  Advanced\n",
            " \n",
            "GIT |  Advanced\n",
            "Gitlab |  Advanced\n",
            " \n",
            "Docker |  Intermediate \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Document into chunks with langchain text splitter"
      ],
      "metadata": {
        "id": "ececRN1yIa0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSplitting the document into smaller chunks...\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,\n",
        "                                               chunk_overlap = 150,\n",
        "                                               separators=[\"\\n\\n\", \"\\n\", \".\"])\n",
        "try:\n",
        "  documents = text_splitter.split_documents(raw_documents)\n",
        "  print(f\"Document splitted into {len(documents)} chunks!\")\n",
        "\n",
        "except:\n",
        "  raise ValueError(\"Error: Splitting resulted in zero.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me0J5s96G-Gh",
        "outputId": "d6e7c254-4d18-4a1a-f7cc-e1a82a06bd0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Splitting the document into smaller chunks...\n",
            "Document splitted into 5 chunks!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Example Chunk (Chunk 1) ---\")\n",
        "print(documents[1].page_content)\n",
        "print(\"\\n--- Metadata for Chunk 1 ---\")\n",
        "print(documents[1].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEjhA5FaKU5n",
        "outputId": "374e4cad-357a-463b-9a8a-dbaee37ef02b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example Chunk (Chunk 1) ---\n",
            "accuracy.\n",
            "- Designing and implementing Windows applications using PyQt for data processing and\n",
            "analysis.\n",
            "- Working on natural language models, including ﬁne-tuning language models for\n",
            "extracting features from tweets.\n",
            "- Collaborating with the team to integrate machine learning models into software\n",
            "environments and optimize their performance.\n",
            "AI researcher July 2022 until February 2023 (7 months)\n",
            "Iranian Research Organization for Science and Technology (IROST) Iran Tehran\n",
            "- Research and development of a model for cardiac arrhythmia detection using\n",
            "Contrastive Learning on EEG data.\n",
            "- Developed a model with strong performance on imbalanced data and minimal label\n",
            "requirements, ensuring efﬁciency in data processing.\n",
            "AI developer October 2020 until January 2022 (1 year and 3 months)\n",
            "Aicell Iran Tehran\n",
            "- Fine-tuned the wave2vec model to develop a conversational AI model for Aicell social\n",
            "robot, designed to assist passengers in airports.\n",
            "\n",
            "--- Metadata for Chunk 1 ---\n",
            "{'producer': 'TCPDF 6.2.5 (http://www.tcpdf.org)', 'creator': 'PyPDF', 'creationdate': '2025-02-15T06:55:31+01:00', 'moddate': '2025-02-15T06:55:31+01:00', 'trapped': '/False', 'source': '/content/drive/MyDrive/resume/Saeed_Lotfi.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings and Vector Store Creation"
      ],
      "metadata": {
        "id": "cNBtkrVNkwax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initializing the Embeddings...\")\n",
        "\n",
        "# Create embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"Embeddings model initialized!\")\n",
        "print(\"\\nCreating Chromadb vector store and embedding documents...\")\n",
        "\n",
        "# Initialize ChromaDB and add documents\n",
        "vectorstore = Chroma.from_documents(documents=documents, embedding=embedding_model, persist_directory=\"./chromadb_store\")\n",
        "\n",
        "vector_count = vectorstore._collection.count()\n",
        "print(f\"ChromaDB vector store created with {vector_count} items.\")\n"
      ],
      "metadata": {
        "id": "KWP2d-xzLDqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6df883-7997-467f-eb43-c89a547b1d61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing the Embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-3673041054>:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings model initialized!\n",
            "\n",
            "Creating Chromadb vector store and embedding documents...\n",
            "ChromaDB vector store created with 10 items.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the first chunk of stored data from the vector store.\n",
        "stored_data = vectorstore._collection.get(include=[\"embeddings\", \"documents\"], limit = 2)\n",
        "\n",
        "print(\"First chunk text:\\n\", stored_data['documents'][1])\n",
        "print(\"\\nEmbedding Vector:\\n\", stored_data['embeddings'][1])\n",
        "print(f\"\\nFull embedding has {len(stored_data['embeddings'][1])} dimensions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1trew2tQrOhr",
        "outputId": "12000e0a-721e-4bce-f068-910227301bc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First chunk text:\n",
            " accuracy.\n",
            "- Designing and implementing Windows applications using PyQt for data processing and\n",
            "analysis.\n",
            "- Working on natural language models, including ﬁne-tuning language models for\n",
            "extracting features from tweets.\n",
            "- Collaborating with the team to integrate machine learning models into software\n",
            "environments and optimize their performance.\n",
            "AI researcher July 2022 until February 2023 (7 months)\n",
            "Iranian Research Organization for Science and Technology (IROST) Iran Tehran\n",
            "- Research and development of a model for cardiac arrhythmia detection using\n",
            "Contrastive Learning on EEG data.\n",
            "- Developed a model with strong performance on imbalanced data and minimal label\n",
            "requirements, ensuring efﬁciency in data processing.\n",
            "AI developer October 2020 until January 2022 (1 year and 3 months)\n",
            "Aicell Iran Tehran\n",
            "- Fine-tuned the wave2vec model to develop a conversational AI model for Aicell social\n",
            "robot, designed to assist passengers in airports.\n",
            "\n",
            "Embedding Vector:\n",
            " [-3.32813002e-02 -1.11399721e-02  3.13355997e-02  5.02064228e-02\n",
            "  8.38021375e-03 -5.78111000e-02 -1.95237994e-02  6.31441688e-03\n",
            "  1.46175809e-02 -4.25989516e-02 -3.93781327e-02 -3.33579518e-02\n",
            "  1.31747387e-02  1.96002629e-02  2.03211661e-02  3.30476873e-02\n",
            "  2.88370848e-02 -6.81434646e-02 -3.76461819e-02 -1.01916328e-01\n",
            " -1.15311975e-02  6.00111894e-02  3.73316221e-02 -1.92359593e-02\n",
            "  1.01171585e-03  4.87607792e-02  1.22926589e-02 -5.83019555e-02\n",
            "  4.09677289e-02  1.15954480e-03  2.13822573e-02 -4.13555317e-02\n",
            "  3.04966494e-02  8.98438245e-02 -6.29126355e-02  9.49328095e-02\n",
            " -4.11328673e-03 -5.80138760e-03 -1.78041623e-03 -1.31327165e-02\n",
            " -3.45700495e-02 -7.93323070e-02 -4.58698943e-02 -2.25093580e-04\n",
            "  9.29605365e-02  2.21998096e-02 -3.55943702e-02 -7.73166865e-02\n",
            " -2.72777118e-02  3.53558697e-02 -1.45073265e-01 -4.34581041e-02\n",
            "  5.87724298e-02  6.85058981e-02 -7.28002712e-02  3.72982547e-02\n",
            " -7.62738381e-03  4.33964394e-02  2.11031567e-02 -2.80134957e-02\n",
            "  9.05137137e-03 -5.46003841e-02  1.66007634e-02  3.74219008e-02\n",
            " -5.05941026e-02  1.90580301e-02 -6.27188534e-02  1.34766083e-02\n",
            "  1.45306457e-02 -6.79732561e-02 -3.58955897e-02  7.24519938e-02\n",
            "  2.79120021e-02  7.32741803e-02 -5.56717478e-02  2.01778971e-02\n",
            "  6.13499619e-02 -4.61087860e-02  1.16124190e-01 -4.74030674e-02\n",
            " -1.56865362e-02 -8.36328119e-02 -1.41576892e-02 -3.11697455e-04\n",
            "  7.12626651e-02  3.18664536e-02 -5.02612889e-02  2.59545967e-02\n",
            " -8.49893764e-02  2.95093358e-02  7.00290054e-02 -1.76890548e-02\n",
            "  9.63243470e-02  2.08820272e-02  2.69935280e-02  4.76360209e-02\n",
            " -1.85981188e-02 -4.33627330e-02 -6.72024414e-02  5.66864386e-02\n",
            " -1.08874235e-02  8.10218304e-02  1.35770030e-02  1.16804913e-02\n",
            " -1.14345569e-02 -3.23245376e-02  8.87725651e-02 -7.04997107e-02\n",
            "  6.56033307e-02 -9.65518430e-02 -5.45661636e-02  1.18809883e-02\n",
            " -1.85018507e-04 -4.76836897e-02  7.92329609e-02  3.48069854e-02\n",
            " -5.25381416e-02  6.27847314e-02  2.10503698e-03  8.28991607e-02\n",
            " -2.47090980e-02 -3.37177478e-02 -2.25291215e-02  5.23662791e-02\n",
            "  6.71061128e-02 -3.37922364e-03 -7.16350898e-02  5.14602701e-33\n",
            "  3.03842662e-05  2.31234077e-02  2.34892555e-02  1.69171244e-02\n",
            "  2.93253325e-02 -5.92336953e-02 -6.07441366e-02  1.77801251e-02\n",
            "  1.79449022e-02 -1.53731024e-02 -1.01658158e-01 -3.99653167e-02\n",
            " -5.02102859e-02  3.97438966e-02  4.24003378e-02 -5.90351149e-02\n",
            " -8.07538852e-02  1.11572025e-02 -2.34697163e-02 -2.39278078e-02\n",
            "  7.39385262e-02 -1.28753334e-01  1.59179065e-02  1.68077443e-02\n",
            "  2.61465926e-02  9.29703489e-02  7.12149218e-02 -2.65997183e-02\n",
            "  3.94246094e-02  2.90291626e-02 -9.74214971e-02  8.81764516e-02\n",
            " -9.02858675e-02 -1.23899318e-02 -3.79461912e-03 -4.04342730e-03\n",
            " -4.99639194e-03  4.91298595e-03 -1.14399539e-02  3.33719552e-02\n",
            " -2.94372402e-02  5.55437878e-02  7.32670128e-02 -9.78868082e-02\n",
            " -1.26181962e-02 -1.39672803e-02  8.65258798e-02 -1.26777980e-02\n",
            "  3.25611383e-02 -4.45073098e-02 -1.75151993e-02 -7.89149944e-03\n",
            " -5.09135425e-02 -6.73352275e-03  4.96817231e-02  2.29519494e-02\n",
            "  1.57296602e-02  7.06810355e-02  2.46375557e-02  4.43586893e-02\n",
            "  3.23650800e-02  5.15913533e-04  4.46080267e-02  5.44801503e-02\n",
            "  5.73842861e-02  3.47454883e-02 -4.75466670e-03  1.88401842e-03\n",
            "  6.71401853e-03  2.73854267e-02  4.82732393e-02  3.12629864e-02\n",
            "  3.43875436e-05  1.61460228e-03 -2.65635960e-02 -2.89545953e-02\n",
            "  3.27984057e-03 -5.04990183e-02  1.01951258e-02  9.16060619e-03\n",
            " -9.16384757e-02  2.67952885e-02  2.80514434e-02 -8.09029713e-02\n",
            "  3.24486718e-02 -7.51917958e-02  1.43165151e-02 -3.28625515e-02\n",
            " -7.71919936e-02  4.35664579e-02 -9.17315111e-02  3.41474824e-02\n",
            " -2.66454578e-03  5.33695035e-02 -2.17249934e-02 -5.00214613e-33\n",
            " -6.38679788e-02  3.41830030e-02 -9.91820320e-02  9.86543205e-03\n",
            "  5.09263501e-02 -4.18382883e-02  1.64512992e-02  3.35335173e-02\n",
            "  3.70606035e-02  2.10860223e-02  4.71257567e-02 -1.80983953e-02\n",
            "  9.00903195e-02  4.30262014e-02  2.55439188e-02  1.02295177e-02\n",
            " -3.90706025e-02 -5.81486262e-02  1.14736399e-02  5.40016666e-02\n",
            " -5.30183986e-02  4.67887595e-02 -7.27703869e-02  2.49196626e-02\n",
            "  2.68084952e-03  5.22229038e-02 -1.40685812e-02 -3.86396460e-02\n",
            " -1.15215871e-02 -7.31512830e-02 -8.85440260e-02 -1.38312094e-02\n",
            " -7.41674751e-02 -2.99036410e-03  1.26646424e-03  2.85072923e-02\n",
            "  2.09126435e-03 -1.28766015e-01  5.70358662e-03  2.62990259e-02\n",
            "  1.33447558e-01  6.80826455e-02 -1.07186519e-01 -2.85773855e-02\n",
            " -2.18667388e-02 -2.03325190e-02 -7.33997524e-02 -2.56630089e-02\n",
            " -3.18376683e-02 -5.54115996e-02  3.16840298e-02  1.30155813e-02\n",
            " -5.40744700e-02 -4.82863486e-02 -5.97202890e-02 -2.26346981e-02\n",
            "  3.93004976e-02  1.42114135e-02 -2.25015357e-02 -2.26449571e-03\n",
            " -9.16244164e-02 -2.85785235e-02  7.61294439e-02 -4.15365919e-02\n",
            " -4.40040082e-02 -2.27275509e-02  2.42890250e-02  9.62273628e-02\n",
            "  4.88305911e-02 -1.88139305e-02  9.14238095e-02 -2.65734233e-02\n",
            " -5.83624393e-02  9.47240070e-02 -3.39105576e-02 -1.72107331e-02\n",
            " -2.44714576e-03 -4.41019461e-02 -4.12370972e-02 -8.30802619e-02\n",
            "  8.35365243e-03  1.74103491e-03  1.63219795e-02  7.36522600e-02\n",
            "  6.54332386e-03  3.49303000e-02  7.72639289e-02 -4.47851606e-02\n",
            " -2.94225980e-02 -1.53485872e-02 -3.50302495e-02  6.59998730e-02\n",
            " -1.61011275e-02  1.20773122e-01 -9.69867036e-02 -4.95471042e-08\n",
            " -5.10458685e-02 -2.14487351e-02  5.59939370e-02  2.02550832e-02\n",
            "  3.21480967e-02 -4.54793572e-02 -6.82733208e-02  3.72489691e-02\n",
            " -7.60626271e-02 -3.78143042e-02  4.04118784e-02 -8.51436239e-03\n",
            "  5.22433175e-03 -2.55841222e-02  5.43954745e-02  3.03766932e-02\n",
            " -4.94749472e-02  5.14715537e-02  2.81964503e-02 -4.91317809e-02\n",
            "  1.31925374e-01 -9.44276154e-03 -2.91391239e-02  5.30836284e-02\n",
            "  7.51931593e-02 -5.47439754e-02 -7.40325451e-02  1.21081062e-02\n",
            " -2.35437062e-02 -6.45275135e-03 -1.91264264e-02  4.78709377e-02\n",
            "  2.81782877e-02 -9.38500836e-03  1.13532282e-01  3.11758760e-02\n",
            "  6.79169549e-04 -1.01751767e-01 -6.58151731e-02  4.90337163e-02\n",
            "  1.76520720e-02  9.54777822e-02 -2.35016532e-02 -2.34820470e-02\n",
            "  2.66139638e-02 -1.49712823e-02  1.44806067e-02 -1.96313769e-01\n",
            "  8.03464353e-02  1.92110464e-02  4.11707126e-02 -3.86719708e-03\n",
            "  3.58715504e-02  4.04130332e-02  1.03553303e-01  4.56225090e-02\n",
            "  1.39354579e-02 -4.09426652e-02 -1.28518129e-02  3.29604335e-02\n",
            "  6.66097105e-02  5.87052666e-02 -6.43007085e-02  3.28916055e-03]\n",
            "\n",
            "Full embedding has 384 dimensions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Retrieval"
      ],
      "metadata": {
        "id": "2tx4jLayzAwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Testing similarity search in vector store ---\")\n",
        "test_query = \"Who is Saeed?\"\n",
        "print(f\"Searching for documents similar to: {test_query}\")\n",
        "\n",
        "try:\n",
        "  similar_docs = vectorstore.similarity_search(test_query, k=2)\n",
        "  print(f\"\\nFound {len(similar_docs)} similar documents:\")\n",
        "\n",
        "  for i, doc in enumerate(similar_docs):\n",
        "    print(f\"\\n--- Documents {i+1} ---\")\n",
        "    content_snippet = doc.page_content[:300].strip() + \"...\"\n",
        "    source = doc.metadata.get(\"source\", \"Unknown Sources!\")\n",
        "    print(f\"Content Snippet: {content_snippet}\")\n",
        "    print(f\"\\nSource: {source}\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62nJmpr1tYXk",
        "outputId": "c8743092-cf94-41df-a0c6-9cc889ccc309"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing similarity search in vector store ---\n",
            "Searching for documents similar to: Who is Saeed?\n",
            "\n",
            "Found 2 similar documents:\n",
            "\n",
            "--- Documents 1 ---\n",
            "Content Snippet: Saeed Lotfi\n",
            "AI developer at Sharif Hamrah\n",
            "Pazhouhan\n",
            "Master : Artiﬁcial intelligence and\n",
            "robotics At K.N.Toosi University of\n",
            "Technology\n",
            "Personal Information\n",
            "Age: 31 Years\n",
            "Gender: Male\n",
            "Location Province: Tehran\n",
            "Location City: Tehran\n",
            "Marital Status: Single\n",
            "Military Service\n",
            "Status:\n",
            "Completed\n",
            "Contact Det...\n",
            "\n",
            "Source: /content/drive/MyDrive/resume/Saeed_Lotfi.pdf\n",
            "\n",
            "--- Documents 2 ---\n",
            "Content Snippet: Saeed Lotfi\n",
            "AI developer at Sharif Hamrah\n",
            "Pazhouhan\n",
            "Master : Artiﬁcial intelligence and\n",
            "robotics At K.N.Toosi University of\n",
            "Technology\n",
            "Personal Information\n",
            "Age: 31 Years\n",
            "Gender: Male\n",
            "Location Province: Tehran\n",
            "Location City: Tehran\n",
            "Marital Status: Single\n",
            "Military Service\n",
            "Status:\n",
            "Completed\n",
            "Contact Det...\n",
            "\n",
            "Source: /content/drive/MyDrive/resume/Saeed_Lotfi.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building & Testing the RAG chain using langchain"
      ],
      "metadata": {
        "id": "lbCIgvpV3dID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\":3})\n",
        "print(\"Retriever configured successfully from vector store!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW2Yt25p3Yv8",
        "outputId": "37ae4200-f8d4-4c53-b6d8-f85a482dd705"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever configured successfully from vector store!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup TinyLlama for generation."
      ],
      "metadata": {
        "id": "rLWBEXh34uab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Create pipeline\n",
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                max_new_tokens=1000,\n",
        "                do_sample=True)\n",
        "\n",
        "# Wrap in LangChain-compatible LLM\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi98hO-C5Hnk",
        "outputId": "b6cb6933-3c06-4387-fc6c-5c9410dccc26"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    return_source_documents=False  # do not return source docs\n",
        ")"
      ],
      "metadata": {
        "id": "9fr540zKFKus"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Introduce Saee Lotfi\"\n",
        "result = qa_chain.run(query)\n",
        "\n",
        "# Extract only the final answer\n",
        "if \"Helpful Answer:\" in result:\n",
        "    answer = result.split(\"Helpful Answer:\")[-1].strip()\n",
        "else:\n",
        "    answer = result.strip()  # fallback\n",
        "\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LABqtfHGFTue",
        "outputId": "fb0a2ff6-946b-45ed-f9b6-cd38f465e0ab"
      },
      "execution_count": 50,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Saeed Lotfi is an AI developer at Sharif Hamrah Pazhouhan. Saeed Lotfi is a Bachelor's degree holder in Electrical Engineering - Electronics from Semnan University and a Master's degree holder in Artificial intelligence and robotics from K.N.Toosi University of Technology. On his LinkedIn page, he has shared his experience and skills since joining the company in 2019. He has also shared his projects on Coursera, where he has completed several courses related to machine learning and deep learning.\n"
          ]
        }
      ]
    }
  ]
}